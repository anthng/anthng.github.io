---
layout: post
title:  Summary of Bayesian Personalized Ranking from Implicit Feedback
excerpt: "A literature review: 'BPR: Bayesian Personalized Ranking from Implicit Feedback'"
categories:
    - Review
tags:
    - Review
    - Recommender-System
comments: true
permalink: blogs/summary-bpr

---

A summary of [BPR: Bayesian Personalized Ranking from Implicit Feedback](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf) [1].

# Personalized Ranking System

The personalized ranking system is a ranked list of recommended items for a customer. The interesting point of personalized ranking is to revolve around positive examples (user has interacted with items, e.g: user bought items in the past), negative examples (the user has not interacted with the items, e.g: the user has not bought an item yet) - a mixture of negative feedback (the user is not interested in buying the item) and missing values (the user might buy the items in the future).

<h2>Contents</h2>

* TOC
{:toc}

# 1. Introduction

Recommender systems are a widely applicable problem in industry such as: music recommendation, movie/video recommendation, point-of-interest (POI) recommendationm and so on. The goal of recommender systems is to provide relevant items based on historical data of users who interacted with them.

In general, most recent works in recommender system foccus on two scenarios:

- **Explicit feedback**: user provides explicit feedback, like: rating.
- **Implicit feedback**: user clicks/purchases/views times (interacts with).

For explicit feedback, not all systems can get explicit user data while implicit feedback is easy to collect because we can track automatically user interactions. In the real world, implicit feedback is already available in almost any information system – e.g. web servers record any page access in log files.

In the implicit scenario, only positive classes are observed. Researchers used binary values to represent the implicit feedback, 1 means positive (observed), while 0 means negative (non-observed). In the other words, if there exists an interaction between user and item, they are labeled a positive (1), and the others are labeled as negative (0).


<a href="../images/posts/bpr/implicit_representation.png" target="_blank">
<img src="../images/posts/bpr/implicit_representation.png" alt="implicit representation" style="max-width: 100%;" class="center"/>
</a>
<p style="text-align: center;" ><b>Figure 1.</b> On the left side, the observed data  <i>S</i> is shown. Learning directly from <i>S</i> is not feasible as only positive feedback is observed. Usually negative data is generated by filling the matrix with 0 values [1]</p>

However, as mentioned above, the negative cases (non-observed) are a mixture of negative feedback (not interested in) and missing values (potential buyers). Thus, this approach will not take into account ranking recommendation in the future.

In this paper, Rendle et al. propose a (BPR) different way to represent the implicit feedback by using item pairs as training data and optimize the rank list using Bayesian probability.

# 2. Problem Formulation

Let $$U$$ and $$I$$ be the set of all users and the set of all items respectively. $$S \subseteq U \times I$$ is the set of implicit feedback (left side of Fig 1).

The task of the recommender system is now to provide the user with a personalized total ranking $$>_u \subset I^2$$ of all items, where $$>u$$ has to meet the properties of a total order:


1. **Totality**: item $$i$$ is preferred over item $$j$$, **or** item $$j$$ is preferred over item $$i$$:

    $$\forall i,j \in I : i \neq j \Rightarrow i >_u j \lor j >_u i $$

2. **Antisymmetry**: item $$i$$ is preferred over item $$j$$, **and** item $$j$$ is preferred over item $$i$$ if and only if both $$i$$ and $$j$$ are the same:

    $$\forall i,j \in I : i >_u j \land j >_u i \Rightarrow i = j $$
 
3. **Transitivity**: **if** item $$i$$ is preferred over item $$j$$ **and** item $$j$$ is preferred over item $$k$$, **then** the user $$u$$ prefers item $$i$$ over $$k$$:

    $$\forall i,j,k \in I : i >_u j \land j >_u k \Rightarrow i >_u k $$

For convenience we also define:

$$I_u^{+} := \{ i \in I : (u,i) \in S \}$$

$$U_i^{+} := \{ u \in I : (u,i) \in S \}$$

Where $$I_u^{+}$$ is set of all items which user $$u$$ interacted with. $$U_i^{+}$$ is set of user has interacted with item $$i$$.

Training data is formalized as follows:

$$D_S = \{(u,i,j) | i \in I_u^+ \land j \in I \setminus I_u^+\}$$

$$D_S$$ is a set of many triples $$(u,i,j)$$. The sematics of $$(u,i,j) \in D_S$$ is that user $$u$$ is assummed to prefer $$i$$ over $$j$$.

<a href="../images/posts/bpr/fig2.png" target="_blank">
<img src="../images/posts/bpr/fig2.png" alt="implicit representation" style="max-width: 100%;" class="center"/>
</a>
<p style="text-align: center;" ><b>Figure 2.</b>Training data for BPR [1]</p>

In the Fig 2, positive sign shows that a user $$u$$ prefers item $$i$$ over item $$j$$. On contrary, negative sign indicates that $$u$$ prefers $$j$$ over $$i$$. For pairs of items that have both been interacted by a user, we can not infer any preference and marked as '?'.

# 3. Bayesian Personalized Ranking (BPR)

Let $$\Theta$$ be the parameter of model. The goal is to maximize posterior probability .

$$\begin{align}p(\Theta | i >_u j) \propto p(i >_u j |\Theta) p(\Theta)
\end{align}$$

Here $$p(i >_u j |\Theta)$$ is a likelihood function, and $$>_u$$ is is the desired but latent preference structure
for user.

Assumming that all users are independent with each other, we can re-write the likelihood function as a product:

$$\prod_{u \in U} p(>_u | \Theta)= p(>_{u_1} | \Theta) p(>_{u_2} | \Theta)…p(>_{u_n} | \Theta)$$

Next, the ordering of each pair of items $$(i, j)$$ for a specific user is independent of the ordering of every other pair. Because there are only two cases $$i>_u j$$ and $$j>_u i$$ (It follows the Bernoulli distribution), we can be expressed as follows:

$$\begin{align*}\prod_{u \in U} p(>_u | \Theta) = \prod_{(u,i,j) \in U \times I \times I} p(i >_u j|\Theta) = \prod_{(u,i,j) \in D_s} p(i >_u j)^{\delta((u,i,j) \in D_S)} (1-p(i >_u j))^{\delta((u,i,j) \notin D_S)} \end{align*}$$

where $$\delta$$ is the indicator function:

$$\begin{align*}\delta((u,i,j) \in D_{S}) &:= \begin{cases}
1 & \mbox{if }(u,i,j) \in D_S \\
0 & \mbox{if }(u,i,j) \notin D_S
\end{cases}
\end{align*}$$

We define the individual probability that a user really prefers item $$i$$ to item $$j$$ by a sigmoid function as:

$$p(i >_u j | \Theta) = \sigma (\hat{x}_{uij}(\Theta))$$

where $$\sigma$$ is the logistic sigmoid:

$$\sigma(x) = \frac{1}{1 + e^{-x}}$$

$$\hat{x}_{uij}(\Theta)$$ captures the special relationship between user $$u$$, item $$i$$, and item $$j$$.

We need prior probability to complete the Bayesian modeling approach of the personalized ranking task. In this work, Rendle et al. introduce $$p(\Theta)$$ which is a normal distribution with zero mean $$(\mu = 0)$$ and variance-covariance matrix $$\Sigma (\Theta)$$, and set $$\Sigma (\Theta) = \lambda_{\Theta} I$$ to reduce the number of unknown hyper-parameters.

As you know, $$\mid \Sigma_{\Theta}\mid = \mid\lambda I\mid = \mid\lambda^d  I\mid  = \lambda^d$$ with $$I$$ is identity matrix, and determinant of identity matrix is 1.

$$p(\Theta) \sim N(\mathbf{0}, \ \lambda_{\Theta}I)$$

$$
\begin{align*}
N(\Theta | \mu, \Sigma)
&= \frac{1}{(2\pi)^{d/2}\sqrt{|\Sigma_{\Theta}|}} exp(-\frac{1}{2}(\Theta-\mu)^{T} \Sigma^{-1}_{\Theta}(\Theta-\mu) ) \\
&= \frac{1}{(2\pi)^{d/2}\sqrt{\lambda^{d}}} exp(-\frac{1}{2}\Theta^{T} (\frac{1}{\lambda_{\Theta}}I) \Theta) \\
&= \frac{1}{(2\pi)^{d/2}\sqrt{\lambda^{d}}} exp(-\frac{1}{2\lambda_{\Theta}}\Theta^{T} \Theta)
\end{align*}
$$

In the formula above, the only part that depends on $$\Theta$$ that is $$ exp(-\frac{1}{2\lambda_{\Theta}}\Theta^{T} \Theta)$$, the remainder is a constant ($$c$$). $$p(\Theta)$$ can be re-written $$- \frac{1}{2} \left\Vert \Theta \right\Vert ^{2}$$ after we take the natural log for both sides:

$$
\begin{align*}
\ln{p(\Theta)} &= \ln{[\frac{1}{(2\pi)^{d/2}\sqrt{\lambda^{d}}} exp(-\frac{1}{2\lambda_{\Theta}}\Theta^{T} \Theta)]} \\
&= c -\frac{1}{2\lambda_{\Theta}}\Theta^{T} \Theta \\
&= - \frac{1}{2\lambda_{\Theta}} \left\Vert \Theta \right\Vert ^{2} +c \\
&\simeq -\lambda_{\Theta} \left\Vert \Theta \right\Vert ^{2} +c

\end{align*}
$$

To sum it all up, the optimization problem will be:

$$\begin{align*}
\text{BPR-OPT} &:= \arg\max_{\Theta} \ p(\Theta|>_u) \\
&= \arg\max_{\Theta} \sum_{(u,i,j) \in D_S } \ln{\sigma (\hat{x}_{uij})} - \lambda_{\Theta} \left\Vert \Theta \right\Vert ^{2}
\end{align*}$$

# 4. BPR Learning Algorithm

In this paper, a stochastic gradient-descent algorithm based on bootstrap sampling of training triples is utilized to optimize model.

```java
procedure LearnBPR(DS, Θ){
    initialize Θ
    while stopping criterion not met {
        Sampling (u,i,j) from DS
        Compute gradient
        Update gradient
    }
    return Θ
}
```
Stochastic gradient descent mathematic formula:

$$\begin{align*}
\Theta \leftarrow \Theta + \alpha \left( \frac{ e^{-\hat{x}_{uij}} }{ 1+e^{-\hat{x}_{uij}} } \cdot \frac{\partial}{\partial \Theta} \hat{x}_{uij} + \lambda_{\Theta} \cdot \Theta \right)
\end{align*}$$

# 5. Learning models with BPR

Matrix factorization in general tries to model the hidden preferences of a user on an item, and it predicts a real number $$\hat{x}_{ul}$$ per user-item pair $$(u,l)$$.

Since our training data are triples $$(u,i,j) \in D_S$$, we need to decompose $$\hat{x}_{uij}$$ as follows:

$$\hat{x}_{uij}= \hat{x}_{ui} - \hat{x}_{uj}$$

Now we can apply any standard collaborative filtering model that predicts $$\hat{x}_{ul}$$.

# References

[1] [BPR: Bayesian Personalized Ranking from Implicit Feedback](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf)
